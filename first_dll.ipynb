{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first dll.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/erconui/cs501r/blob/master/first_dll.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "RLWT5ZpwgK4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "0a5465ca-4de4-4b4a-cc29-358e4e8e57dd"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch \n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.26.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "96fllQAiez3q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "assert torch.cuda.is_available() # You need to request a GPU from Runtime > Change Runtime Type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sqfzWKGVcHyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, \n",
        "               padding=0, dilation=1, groups=1, bias=True):\n",
        "    self.__dict__.update(locals())\n",
        "    super(Conv2d, self).__init__()\n",
        "    \n",
        "    self.weight = Parameter(torch.Tensor(out_channels, in_channels,\n",
        "                                         *kernel_size))\n",
        "    \n",
        "    self.bias = Parameter(torch.Tensor(out_channels))\n",
        "    \n",
        "#     ## Uniform Initialization\n",
        "#     self.weight.data.uniform_(-1,1)\n",
        "#     self.bias.data.uniform_(0,0)\n",
        "    ## XE Initialization\n",
        "    self.weight.data.fill_(0.01)\n",
        "    self.bias.data.fill_(0.01)\n",
        "    ## Orthogonal Initialization\n",
        "#     nn.init.orthogonal(self.weight.data)\n",
        "#     X = np.random.random((out_channels, in_channels*kernel_size[0]*kernel_size[1]))\n",
        "#     U, _, VT = np.linalg.svd(X,full_matrices=False)\n",
        "#     if out_channels > in_channels*kernel_size[0]*kernel_size[1]:\n",
        "#       weight = U.reshape((out_channels, in_channels, kernel_size[0], kernel_size[1]))\n",
        "#     else:\n",
        "#       weight = VT.reshape((out_channels, in_channels, kernel_size[0], kernel_size[1]))\n",
        "#     self.weight = Parameter(torch.tensor(weight).float())\n",
        "      # do it in numpy, bring in numpy orthogonal weight matrix\n",
        "    \n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    return F.conv2d(x, self.weight, self.bias, self.stride, self.padding,\n",
        "                    self.dilation, self.groups)\n",
        "  \n",
        "  def extra_repr(self):\n",
        "    return '501r is so cool'\n",
        "\n",
        "class CrossEntropyLoss(nn.Module):\n",
        "  def __init__(self, weight=None, size_average=None, ignore_index=-100,reduce=None, reduction='elementwise_mean'):\n",
        "    super(CrossEntropyLoss, self).__init__()\n",
        "    \n",
        "  def forward(self, x, labels):\n",
        "    alpha = 0 # torch.max(x)\n",
        "    softmax = -torch.log(torch.exp(x-alpha)/torch.exp(x-alpha).sum(1, keepdim=True))\n",
        "    r = torch.arange(softmax.size(0))\n",
        "    return softmax[r, labels].mean()\n",
        "  \n",
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(ConvNetwork, self).__init__()\n",
        "    x, y = dataset[0]\n",
        "    c,h,w = x.size()\n",
        "    output = 10\n",
        "    \n",
        "    self.net = nn.Sequential(\n",
        "      Conv2d(c, 100, (3,3), padding=(1,1)),\n",
        "      nn.ReLU(),\n",
        "      Conv2d(100, output, (28,28), padding=(0,0))\n",
        "    )\n",
        "   \n",
        "  def forward(self, x):\n",
        "    return self.net(x).squeeze(2).squeeze(2)\n",
        "\n",
        "class FashionMNISTProcessedDataset(Dataset):\n",
        "  def __init__(self, root, train=True):\n",
        "    self.data = datasets.FashionMNIST(\n",
        "        root, train=train, transform=transforms.ToTensor(), download=True)\n",
        "#     self.e = torch.eye(10)\n",
        "    \n",
        "  def __getitem__(self, i):\n",
        "    x, y = self.data[i]\n",
        "#     pdb.set_trace()\n",
        "    return x, y\n",
        "#     return x, self.e[y].float()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QTGCuMiDcRED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61259ae7-0b3e-4e91-b7b4-42a8b99515e1"
      },
      "cell_type": "code",
      "source": [
        "train_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=True)\n",
        "val_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=False)\n",
        "\n",
        "model = ConvNetwork(train_dataset)\n",
        "model.cuda()\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=42, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=42, pin_memory=True)\n",
        "\n",
        "losses = []\n",
        "validations = []\n",
        "accuracies = []\n",
        "val_accuracies = []\n",
        "for epoch in range(1):\n",
        "  loop = tqdm(total=len(train_loader), position=0)\n",
        "  for batch, (x, y_truth) in enumerate(train_loader):\n",
        "    x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    y_hat = model(x)\n",
        "    \n",
        "    loss = objective(y_hat,y_truth)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    losses.append(loss)\n",
        "    accuracy = (torch.softmax(y_hat, 1).argmax(1) == y_truth).float().mean()\n",
        "    accuracies.append(accuracy)\n",
        "    loop.set_description('loss:{:.4f}'.format(loss.item()))\n",
        "    loop.update(1)\n",
        "\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch % 500 == 0:\n",
        "      vals = []\n",
        "      tmp_accuracies = []\n",
        "      for x1,y in val_loader:\n",
        "        x1, y_truth1 = x1.cuda(async=True), y.cuda(async=True)\n",
        "        y_hat = model(x1)\n",
        "        tmp = objective(y_hat, y_truth1).item()\n",
        "        vals.append(tmp)\n",
        "        accuracy = (y_hat.argmax(1) == y_truth1).float().mean()\n",
        "        tmp_accuracies.append(accuracy)\n",
        "                    \n",
        "      val_accuracies.append((len(losses), np.mean(tmp_accuracies)))\n",
        "      validations.append((len(losses), np.mean(vals)))\n",
        "\n",
        "  loop.close()\n",
        "\n",
        "a, b = zip(*validations)\n",
        "# fig, ax = plt.subplots(1,2)\n",
        "plt.plot(losses, label='train')\n",
        "plt.plot(a, b, label='val')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(accuracies, label='training accuracy')\n",
        "a, b = zip(*val_accuracies)\n",
        "plt.plot(a, b, label=\"validation accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:0.5222:  45%|████▌     | 648/1429 [00:31<00:33, 23.52it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kuarzmKqmlwo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Cross Entropy loss\n",
        "# check it outputs the same as pytorch's crossentropyloss\n",
        "\n",
        "#necessary for the soft max\n",
        "a = torch.from_numpy(np.random.randn(3,4,1).astype(np.float32))\n",
        "b = torch.exp(a)\n",
        "z = a / b.sum(1, keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D__Cy79Wtew4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 4\n",
        "## Using a Kernel size of 3×3 what should the settings of your 2d convolution be that results in the following mappings (first answer given to you)\n",
        "\n",
        " (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(3, 3), padding=(0, 0))\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=65, h=12, w=12) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=7, h=20, w=20) : \n",
        "\n",
        "## Using a Kernel size of 5×5:\n",
        "\n",
        " (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(5, 5), padding=(1, 1))\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : \n",
        "\n",
        "## Using Kernel size of 5×3:\n",
        "\n",
        " (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : \n",
        "\n",
        "## Determine the kernel that requires the smallest padding size to make the following mappings possible:\n",
        "\n",
        " (c=3, h=10, w=10) ⇒ (c=10, h=9, w=7) :\n",
        "\n",
        "(c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) : "
      ]
    }
  ]
}